{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Copia de Metropolis-Hastings: Burger Dome Example.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_wbQlRXM244z"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uemyf_0obgHW"
      },
      "source": [
        "## Structure of a Waiting Line System \n",
        "\n",
        "*Information from:\n",
        "**Quantitative Methods for Business**,\n",
        "Twelfth Edition\n",
        "David R. Anderson, Dennis J. Sweeney,\n",
        "Thomas A. Williams, Jeffrey D. Camm,\n",
        "James J. Cochran, Michael J. Fry,\n",
        "Jeffrey W. Ohlmann*\n",
        "\n",
        "\n",
        "To illustrate the basic features of a waiting line model, we consider the waiting line at the Burger Dome fast-food restaurant. Burger Dome sells hamburgers, cheeseburgers, french fries, soft drinks, and milk shakes, as well as a limited number of specialty items and dessert selections. Although Burger Dome would like to serve each customer immediately, at times more customers arrive than can be handled by the Burger Dome food service staff. Thus, customers wait in line to place and receive their orders.\n",
        "\n",
        "Burger Dome is concerned that the methods currently used to serve customers are resulting in excessive waiting times and a possible loss of sales. Management wants to conduct a waiting line study to help determine the best approach to reduce waiting times and improve service.\n",
        "\n",
        "### Single-Server Waiting Line \n",
        "\n",
        "In the current Burger Dome operation, an employee takes a customer’s order, determines the total cost of the order, receives payment from the customer, and then fills the order. Once the first customer’s order is filled, the employee takes the order of the next customer waiting for service.\n",
        "\n",
        "This operation is an example of a single-server waiting line. Each customer entering the Burger Dome restaurant is served by a single order-filling station that handles order placement, bill payment, and food delivery. When more customers arrive than can be served immediately, they form a waiting line and wait for the order-filling station to become\n",
        "available. \n",
        "\n",
        "\n",
        "![im](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/Captura%20de%20pantalla%20de%202020-11-12%2010-29-49.png)\n",
        "\n",
        "## Distribution of Arrivals\n",
        "Defining the arrival process for a waiting line involves determining the probability distribution for the number of arrivals in a given period of time. For many waiting line situations,the arrivals occur randomly and independently of other arrivals, and we cannot predict when an arrival will occur. In such cases, analysts have found that the Poisson probability distribution provides a good description of the arrival pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eckStAb6bgHY"
      },
      "source": [
        "### Exercise\n",
        "Determine the parameters of the Poisson Distribution for the following data on the entry of Customers in Burger Dome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wbQlRXM244z"
      },
      "source": [
        "# Packages installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jGg8JSy2Aqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736a4f7c-a460-4315-a4bd-d68958da17a3"
      },
      "source": [
        "!pip install pymc3==3.8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymc3==3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/19/6c94cbadb287745ac38ff1197b9fadd66500b6b9c468e79099b110c6a2e9/pymc3-3.8-py3-none-any.whl (908kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (1.4.1)\n",
            "Collecting arviz>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/05/54183e9e57b0793eceb67361dbf4a7c4ed797ae36a04a3287791a564568c/arviz-0.10.0-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (1.1.4)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (4.41.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (2.10.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (0.5.1)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from pymc3==3.8) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from arviz>=0.4.1->pymc3==3.8) (20.4)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from arviz>=0.4.1->pymc3==3.8) (3.2.2)\n",
            "Collecting netcdf4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/39/3687b2ba762a709cd97e48dfaf3ae36a78ae603ec3d1487f767ad58a7b2e/netCDF4-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.6/dist-packages (from arviz>=0.4.1->pymc3==3.8) (50.3.2)\n",
            "Collecting xarray>=0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/cc/62ca520e349e63b05ce43c781757cbd3bea71d83ece96f2176763b57e8c2/xarray-0.16.1-py3-none-any.whl (720kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3==3.8) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3==3.8) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.7.0->pymc3==3.8) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->arviz>=0.4.1->pymc3==3.8) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz>=0.4.1->pymc3==3.8) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz>=0.4.1->pymc3==3.8) (1.3.1)\n",
            "Collecting cftime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/60/bad8525d2c046eb2964911bc412a85ba240b31c7b43f0c19377233992c6c/cftime-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 48.4MB/s \n",
            "\u001b[?25hInstalling collected packages: cftime, netcdf4, xarray, arviz, pymc3\n",
            "  Found existing installation: xarray 0.15.1\n",
            "    Uninstalling xarray-0.15.1:\n",
            "      Successfully uninstalled xarray-0.15.1\n",
            "  Found existing installation: pymc3 3.7\n",
            "    Uninstalling pymc3-3.7:\n",
            "      Successfully uninstalled pymc3-3.7\n",
            "Successfully installed arviz-0.10.0 cftime-1.3.0 netcdf4-1.5.4 pymc3-3.8 xarray-0.16.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V7A76KoDQHV"
      },
      "source": [
        "# Data Exploration\n",
        "\n",
        "In the data base we can find the arrival register in one day in the Burger Dome. We assume that the meditions are mainly correct, then the times that are not in the data base will are take as moments without arrivals or moments with zero arrivals. Thus, we can take an indicator that counts the number of arrivals by an given intervals of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDzLNc62bgHa"
      },
      "source": [
        "# numpy and pandas for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# scipy for distributions and algorithms\n",
        "import scipy\n",
        "from scipy import optimize\n",
        "import scipy.stats as ss\n",
        "\n",
        "# pymc3 for model implementation\n",
        "import pymc3 as pm\n",
        "import theano.tensor as tt\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = (10, 3)\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['ytick.major.size'] = 20\n",
        "plt.style.use(\"seaborn-deep\")\n",
        "\n",
        "# data reading\n",
        "Data = pd.read_csv('https://raw.githubusercontent.com/Izainea/visualizacion/master/Clients.csv',index_col='Unnamed: 0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nMAXFHCh9Df"
      },
      "source": [
        "# timeline construction\n",
        "Data1=np.array(Data)\n",
        "time = []\n",
        "for i in range(7,20):     # takes the range of time from 7:00 am to 20:00 pm\n",
        "  for j in range(60):     # Hours of 60 minutes\n",
        "    for k in range(60):   # Minutes of 60 seconds\n",
        "      if i<10:\n",
        "        if j<10:\n",
        "          if k<10:\n",
        "            time.append(\"0\"+str(i)+\":0\"+str(j)+\":0\"+str(k))\n",
        "          else:\n",
        "            time.append(\"0\"+str(i)+\":0\"+str(j)+\":\"+str(k))\n",
        "        else:\n",
        "          if k<10:\n",
        "            time.append(\"0\"+str(i)+\":\"+str(j)+\":0\"+str(k))\n",
        "          else:\n",
        "            time.append(\"0\"+str(i)+\":\"+str(j)+\":\"+str(k))\n",
        "      else:\n",
        "        if j<10:\n",
        "          if k<10:\n",
        "            time.append(str(i)+\":0\"+str(j)+\":0\"+str(k))\n",
        "          else:\n",
        "            time.append(str(i)+\":0\"+str(j)+\":\"+str(k))\n",
        "        else:\n",
        "          if k<10:\n",
        "            time.append(str(i)+\":\"+str(j)+\":0\"+str(k))\n",
        "          else:\n",
        "            time.append(str(i)+\":\"+str(j)+\":\"+str(k))\n",
        "\n",
        "# The indicator of arrivals\n",
        "indicador = []\n",
        "for i in time:\n",
        "  if i in Data1:\n",
        "    indicador.append(1)   # As the all arrivals are in different times, just take 1 arrival in the true case\n",
        "  else:\n",
        "    indicador.append(0)\n",
        "\n",
        "Data = pd.DataFrame({\"Tiempo\":time,\"Indicador\":indicador})\n",
        "Data[370:375]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN45vEGnoohi"
      },
      "source": [
        "![texto del enlace](https://photos.google.com/album/AF1QipMrxzBSFWr4qZGlHDVDdXIJRZaFSQNC-o5E00sw/photo/AF1QipPgVNWctXD4YTwY-CjXo7RLR6NsmrVVyCW2q5Vc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa4jeIR6047Y"
      },
      "source": [
        "# The time intervals construction\n",
        "n = 1   # length of intervals in minutes\n",
        "m = int(12*60/n)\n",
        "k = 0\n",
        "lim = [k]\n",
        "for i in range(m):\n",
        "  k += n\n",
        "  if k >= 60:\n",
        "    break\n",
        "  lim.append(k)\n",
        "\n",
        "# Writing of extremals of the intervals\n",
        "time1 = []\n",
        "for i in range(7,20):\n",
        "  for j in lim:\n",
        "    if i<10:\n",
        "      if j<10:\n",
        "        time1.append(\"0\"+str(i)+\":0\"+str(j)+\":00\")\n",
        "      else:\n",
        "        time1.append(\"0\"+str(i)+\":\"+str(j)+\":00\")\n",
        "    else:\n",
        "      if j<10:\n",
        "        time1.append(str(i)+\":0\"+str(j)+\":00\")\n",
        "      else:\n",
        "        time1.append(str(i)+\":\"+str(j)+\":00\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3vMAE6VMgZg"
      },
      "source": [
        "## Arrivals Data\n",
        "\n",
        "Using a histogram, we can describe correctly the data of arrivals in the choose time intervals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zl_SLOkvVD0"
      },
      "source": [
        "# The lists of arrivals by time interval\r\n",
        "time_boxes = []   # times\r\n",
        "indi_boxes = []   # arrivals\r\n",
        "\r\n",
        "for i in range(len(time1)-1):\r\n",
        "  A = []   # time interval \r\n",
        "  B = []\r\n",
        "  for j in range(len(time)):\r\n",
        "    if time1[i] < time[j] < time1[i+1]:   # if the medition are in the interval return True\r\n",
        "      A.append(time[j])\r\n",
        "      B.append(indicador[j])\r\n",
        "  time_boxes.append(A)\r\n",
        "  indi_boxes.append(B)\r\n",
        "\r\n",
        "# Number of arrivals by time interval\r\n",
        "counts = []\r\n",
        "for i in indi_boxes:\r\n",
        "  counts.append(sum(i))\r\n",
        "\r\n",
        "print(\"The number of intervals are %d\" %len(counts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgdBXXprvRuo"
      },
      "source": [
        "The number of intervals are 779"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsbL_oxZvO13"
      },
      "source": [
        "# number of clients for probability prediction\r\n",
        "arrivals_est = range(7)\r\n",
        "\r\n",
        "# Data for bar plots\r\n",
        "count_norm = []\r\n",
        "for i in range(len(arrivals_est)):\r\n",
        "  k = counts.count(i)\r\n",
        "  count_norm.append(k/len(counts))\r\n",
        "\r\n",
        "figsize(16,6)\r\n",
        "\r\n",
        "# Histogram of arrivals in the Burger Dome\r\n",
        "plt.title(\"Bar plot for buyer income\")\r\n",
        "plt.xlabel(\"Number of buyers in %d minute intervals\" %n)\r\n",
        "plt.ylabel(\"Frequency\")\r\n",
        "#plt.hist(counts, density=True,bins=5)\r\n",
        "plt.bar(range(7),count_norm,label=\"obs\")\r\n",
        "plt.ylim(top=1)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTeg6VPevIe1"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vT5lY50lYyqErYGvbiThZT9UHlTSsVEq3A1uNwDwixMOeMnWIx1gnFDerqxofws7nrLJYfC3n6finVw/pub?w=900&h=377)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTd8pRu7DeFo"
      },
      "source": [
        "## Poisson Distribution\n",
        "\n",
        "It seems that we can model the number of arrivals with a Poisson distribution, let's remember that the Poisson distribution is a discrete distribution with parameter $\\lambda$, where $\\lambda$ represents the mean number of ocurrences of the event in a given time interval (note that $\\lambda\\in(0,\\infty)$). The density function of this distribution is given by\n",
        "\n",
        "$$P_\\lambda(x)=\\left\\{\\begin{array}{cl}\n",
        "\\frac{e^{-\\lambda}\\lambda^x}{x!} & \\text{if }x=0,1,2,\\cdots \\\\\n",
        "0 & \\text{in other case}\n",
        "\\end{array}\\right.$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW8Zn2wID2Vw"
      },
      "source": [
        "x = range(0, 25)   # example domain of P\n",
        "lam = (0.5,4,8,15)   # example values of lambda\n",
        "colors = (\"royalblue\", \"mediumaquamarine\", \"teal\", \"darkslategrey\")\n",
        "\n",
        "params=zip(lam,colors)\n",
        "for param in params:\n",
        "  y = []\n",
        "  for i in x:\n",
        "    P=ss.poisson(param[0])   # the Poisson distribution from scipy \n",
        "    y.append(P.pmf(i))\n",
        "  plt.plot(x, y,\n",
        "  label=r\"$\\lambda$ = %.1f\" % param[0], \n",
        "           color = param[1])\n",
        "  plt.fill_between(x, y, color = param[1], alpha = 0.3)\n",
        "\n",
        "plt.legend(prop={'size':18});\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"Probability Density\", size = 18)\n",
        "plt.ylim(top=1)\n",
        "plt.title(\"Poisson Distributions\", size = 20);\n",
        "\n",
        "plt.show()         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pbdvKxqvzui"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vS1BS7GNo0qZvY-pnS0_Nc0cYFQ8GloA32VJp0ISd9SS-e79lxnQg3PyGlNCzfTz5q2rGesy6eKAKnq/pub?w=902&h=376)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgEzAOTUZv2p"
      },
      "source": [
        "The Poisson distribution has the next properties:\n",
        "\n",
        "*   Let X a random variable with Poisson distribution, then $E[X]=\\lambda=Var(X)$, in other words, the mean of a random variable is equal to its variance.  \n",
        "*   The Poisson distribution can be approximated by a Binomial distribution with adequate probability $p$ small enough and for $n$ big enough.\n",
        "\n",
        "$$\\begin{array}{ccc}\\mathcal{B}_{n,p(n)}(k) & \\overrightarrow{\\small{n\\to\\infty}} & P_\\lambda(k)\\end{array}$$\n",
        "\n",
        "***Observation:*** In our problem, the parameter $\\lambda$ is unknown and will be estimated using Markov Chain Monte Carlo sampling, which is expose later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cOGWiBEMsdo"
      },
      "source": [
        "# Bayesian approach\n",
        "\n",
        "Before delving into Bayesian inference, we must keep in mind the basic notion of the Bayes theorem, which establishes a relationship between the probability that an event $\\theta$ given $X$ will occur with the probability that $X$ given $\\theta$ will occur, formally\n",
        "\n",
        "$$P(\\theta|X)=\\frac{P(X|\\theta)P(\\theta)}{P(X)}$$\n",
        "\n",
        "Where $P(\\theta)$ is called prior probability and $P(\\theta|X)$ is called the posterior probability.\n",
        "\n",
        "The inferential approach is to interpret $X$ as a set of known data, and $\\theta$ as an unknown value of interest (can be one or more parameters, missing measurements, ...) \n",
        "\n",
        "Our main goal is to find or estimate the value of $\\theta$ via the final distribution \n",
        "\n",
        "$$p(\\theta|x)$$\n",
        "\n",
        "For this, we will postulate a probability model $p(x|\\theta)$, a $p(\\theta)$ distribution that adequately describes $\\theta$ so that the initial uncertainty about its value is present and finally the $X$ data, which are conditioned to its observed value $x$, and then use the Bayes theorem and be able to conclude about our value $\\theta$.\n",
        "\n",
        "## Prior distribution for $\\lambda$\n",
        "\n",
        "Because we don't know a distribution for the average number of customer arrivals, $\\lambda$, we can assume that its distribution is of the normal type.\n",
        "\n",
        "The normal distribution belongs to the continuous distribution family; depends on two parameters: the average $\\mu$ and the standard deviation $\\sigma$, which are usually known as localization and scale parameters respectively; density function for normal distribution is given by  \n",
        "\n",
        "$$f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{exp}\\left[-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right]\\text{; }x\\in\\mathbb{R}$$\n",
        "\n",
        "Probability density functions for four normal distributions are shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--70Q2V0W7sk"
      },
      "source": [
        "N = ss.norm    # the normal distribution from scipy\n",
        "x = np.linspace(-10, 10, 1000)   # example domain of N\n",
        "mu = (-3, -2, 0, 2)   # example means\n",
        "sigma = (0.5, 0.75, 1, 1.5)   # example sd\n",
        "colors = (\"royalblue\", \"mediumaquamarine\", \"teal\", \"darkslategrey\")\n",
        "\n",
        "params = zip(mu, sigma, colors)\n",
        "for param in params:\n",
        "    y = N.pdf(x, loc = param[0], scale = param[1])\n",
        "    plt.plot(x, y, \n",
        "             label=\"$\\mu = %d,\\;\\\\sigma = %.1f$\" % (param[0], param[1]), \n",
        "             color = param[2])\n",
        "    plt.fill_between(x, y, color = param[2], alpha = 0.3)\n",
        "    \n",
        "plt.legend(prop={'size':18});\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"Probability Density\", size = 18)\n",
        "plt.xlim(left=-5,right=7.5)\n",
        "plt.ylim(top=1)\n",
        "plt.title(\"Normal Distributions\", size = 20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc7hLh_BwL2g"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vS87dFKM0v2UrBK05sgvQsj57Pvd3eWnRXfDf0AusKJ3toQxlSw9dgdcf1WMuWmuElQ-8htvpHHNLCF/pub?w=900&h=371)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxpdVTob7WIV"
      },
      "source": [
        "# MCMC methods\n",
        "\n",
        "## Markov chains\n",
        "\n",
        "A markov chains is a sequence of random variables $\\{X_n\\}_n$ such that the markov property is satisfied, which tells us that\n",
        "\n",
        "$$P(X_n=x_n|X_{n-1}=x_{n-1},X_{n-2}=x_{n-2},\\cdots,X_0=x_0)=P(X_n=x_n|X_{n-1}=x_{n-1})$$\n",
        "\n",
        "where $x_i$ is the state of $X_i$ in the iteration $i$.\n",
        "\n",
        "The chains Markov can be classification in two types, homogeneous and inhomogeneous. The homogeneous Markov chains are chains Markov with the property what for all states $x_i$ and $x_j$, the probability of pass from state $x_i$ to state $x_j$ do not depends by time, in sense that\n",
        "\n",
        "$$P(X_n=x_j|X_{n-1}=x_i)=P(X_1=x_j|X_0=x_i)$$\n",
        "\n",
        "## What are MCMC methods?\n",
        "\n",
        "Generally, MCMC's or Markov Chain Monte Carlo are methods for sampling distributions using Markov strings, mainly used in Bayesian inference and numerical integration.\n",
        "\n",
        "MCMC's aim to build intelligently sampled strings, via a likelihood indicator, this indicator allows the choice of most likely samples in relation to the data set available to us.\n",
        "\n",
        "## The Metropolis Hastings algorithm\n",
        "\n",
        "The Metropolis Hastings algorithm belongs to the MCMC method set. It is used to produce random samples from a distribution where sampling would be difficult.\n",
        "\n",
        "Generally, the algorithm generates a Markov chain with a stationary distribution, say $\\pi$, in which each iteration consists of two steps: propose a new state of $\\theta$ given a status of $\\theta_k$ and accept or reject it, according to the principle of plausibility, which tells us that the values of $\\theta$ that assign a high probability to observation $x$ are more plausible than the values of $\\theta$ that assign a small probability to $x$.\n",
        "\n",
        "Before enunciating the Metropolis hasting algorithm, we must propose a density function $q$, which will act as a way to move randomly, through the space of possible values of $\\theta$, as we perform the process of finding the acceptance values, knowing the current state of each iteration.\n",
        "\n",
        "### The algorithm MH\n",
        "\n",
        "1.   Given a value of $\\theta_k$, simulate a $\\theta$ candidate of a density $q(\\theta|\\theta_k)$.\n",
        "2.   Calculate the probability of acceptance for the generated value $\\theta$\n",
        "\n",
        "$$\\alpha=\\text{min}\\left\\{1,\\frac{\\pi(\\theta|x)q(\\theta_k|\\theta)}{\\pi(\\theta_k|x)q(\\theta|\\theta_k)}\\right\\}$$\n",
        "\n",
        "3.   Simulate a value $u$ of a uniform distribution  $\\mathcal{U}(0,1)$.\n",
        "4.   Si $u<\\alpha$, take $\\theta_{k+1}=\\theta$, otherwise take $\\theta_{k+1}=\\theta_k$.\n",
        "5.   Go back to 1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWOHLT5IzAD9"
      },
      "source": [
        "# Posterior probability for the arrival of people\n",
        "\n",
        "We now have all the tools to determine the subsequent probability $P(\\theta|X)$. Although we don't yet know the value of the $\\lambda$ parameter, we'll use Poisson's distribution to describe customers' arrival at the Burger Dome. We will use the MCMC methods to determine the value of $\\lambda$ based on the assumption that it is normally distributed with average $\\mu$ and standard deviation $\\sigma$.\n",
        "\n",
        "Python gives us an easy way to implement MCMC methods. The PyMC3 library is a powerful tool to implement these and other inferential algorithms. In the following code we will implement the MH algorithm, which will draw an arbitrary number of samples for $\\lambda$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lotb3wBg-mh2"
      },
      "source": [
        "# number of samples\n",
        "N_samples = 50000 \n",
        " \n",
        "# the array with the number of arrivals by time interval\n",
        "arrivals_obs = np.array(counts)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdLvQLRBitQG"
      },
      "source": [
        "# the Burger Dome model \n",
        "with pm.Model() as burger_model:\n",
        "  # create the parameter lambda\n",
        "  lam = pm.Normal('$\\lambda$', mu=0.001, sigma=1)\n",
        "\n",
        "  # the Poisson distribution for the probability\n",
        "  p = pm.Poisson('p',lam, observed=arrivals_obs)\n",
        "\n",
        "  # using Metropolis Hastings Sampling\n",
        "  step = pm.Metropolis()\n",
        "\n",
        "  # sample from the posterior using the sampling method\n",
        "  burger_trace = pm.sample(N_samples, step=step);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCj4ssYfwUjx"
      },
      "source": [
        "Sequential sampling (2 chains in 1 job)\r\n",
        "\r\n",
        "Metropolis: [\\$\\lambda\\$]\r\n",
        "\r\n",
        "Sampling chain 0, 0 divergences: 100%|██████████| 50500/50500 [00:08<00:00, 6254.23it/s]\r\n",
        "\r\n",
        "Sampling chain 1, 0 divergences: 100%|██████████| 50500/50500 [00:07<00:00, 6870.61it/s]\r\n",
        "\r\n",
        "The number of effective samples is smaller than 10% for some parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjWtb8eRAMTG"
      },
      "source": [
        "The variable burger_trace contains all the samples of $\\lambda$, the idea of MCMC methods is that as the algorithm iterates, the samples become more likely. Next we will perform a histogram that will allow us to inspect the behavior of the samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehLtXG-aCeio"
      },
      "source": [
        "# Extract the lambda samples\n",
        "lam_samples = burger_trace[\"$\\lambda$\"][50000:, None]\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.title(r\"\"\"Distribution of $\\lambda$ with %d samples\"\"\" % N_samples)\n",
        "plt.hist(lam_samples, histtype='stepfilled',color=\"darkolivegreen\",\n",
        "         bins=30, alpha=0.8, density=True);\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuY9n73Ww-Kg"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vQLc7UiF8iwWVbsHFoHUuCBAl2BjFqCoc1fdphfzOoWRkL_s-Jqz0DoHh4w5PoygW04t_YHM6ryz6TZ/pub?w=901&h=191)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAOMtM6F-9qe"
      },
      "source": [
        "It is important to mention that the value we take as an initial condition can alter the convergence speed of our algorithm, usually considered a relatively large amount of iterations to ensure convergence, however, as our goal is to make inferences from the accepted values, the information present in the $50\\%$ can cause biases in our predictions , for this reason we can find examples in which this data is simply extracted from the analysis performed. These values are known as burned values or burn values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C0PvKsNlLzw"
      },
      "source": [
        "# Trace for lambda values\n",
        "plt.subplot(211)\n",
        "plt.title(r'Distribution of $\\lambda$')\n",
        "plt.plot(lam_samples[int(len(lam_samples)/2):], \n",
        "         color = 'darkslategrey', alpha=0.8)\n",
        "plt.xlabel('Samples'); plt.ylabel('Parameter');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZexJA8YTxUGS"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vRn2TlPESjksLbwLYYG0-6wk7eu9jUwRA_FF2pczVGhIjg24tptYWz6Bw3Z8gS9eaMrePrKv2_Sg8-Q/pub?w=900&h=208)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_iXwZsWD62R"
      },
      "source": [
        "We can see that the most likely values for $\\lambda$ are around $0.4$, this we can interpret as that every 15 minutes, on average $0.4\\cdot(15\\text{ minutes})=6$ customers arrive, this because according to the observations and the model implemented, it is less likely that $0.35\\cdot15\\approx5$ people will enter. To find the most likely subsequent distribution for the arrival of customers at the Burger Dome, we will take the average samples of $\\lambda$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrE4P1TtLV0h"
      },
      "source": [
        "# samples with no burning values\n",
        "lam_samples = lam_samples[int(len(lam_samples)/2):]\n",
        "\n",
        "# Consider the most probable parameter as the mean value\n",
        "lam_est = lam_samples.mean()\n",
        "\n",
        "# Probability at each time using mean value of lambda\n",
        "entradas_est = ss.poisson(lam_est).pmf(arrivals_est)\n",
        "\n",
        "print(\"On average, every minute %.3f people arrive\" %lam_est)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEbWjIRTxbHd"
      },
      "source": [
        "On average, every minute 0.408 people arrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2fImynrJW6R"
      },
      "source": [
        "figsize(16,6)\n",
        "# Poisson model with Teacher's parameter\n",
        "entradas_est1 = ss.poisson(0.5).pmf(arrivals_est)  \n",
        "\n",
        "# most probable Poisson model\n",
        "plt.plot(arrivals_est, entradas_est, color = 'navy', \n",
        "         lw=3, label=\"Most probable Poisson model\")\n",
        "plt.plot(arrivals_est, entradas_est1,'r--',\n",
        "         lw=3, label=\"Poisson model with $\\lambda$=0.5\")\n",
        "\n",
        "# histogram for the number of arrivals per time interval\n",
        "#plt.hist(counts, density=True, label=\"Obs\",bins=3)\n",
        "plt.bar(arrivals_est,count_norm,label=\"obs\")\n",
        "\n",
        "plt.legend(prop={'size':18})\n",
        "plt.xlabel(\"People entering the system at %d minute intervals\" %n)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Probability distribution of arrivals with %d samples\" %N_samples)\n",
        "plt.ylim(top=1)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dwWFnYSxscr"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vQp27yc09wZsKcrXoMoyH_KsC2zcnA6Pgt6-9SkFs1wxpL-INESATuQRWJ16h6zvDlOGLloKUO_PVvn/pub?w=904&h=375)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpogJIpJwFQz"
      },
      "source": [
        "Posterior allows us to know the probability for the arrival of an n number of people per minute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbCzKVfAV9oo"
      },
      "source": [
        "print('The probability of a person coming: {:.2f}%.'.\n",
        "      format(100 * ss.poisson(lam_est).pmf(1)))\n",
        "print('The probability of three people arriving: {:.2f}%.'.\n",
        "      format(100 * ss.poisson(lam_est).pmf(3)))\n",
        "print('The probability that no one will arrive: {:.2f}%.'.\n",
        "      format(100 * ss.poisson(lam_est).pmf(0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geSO9g_zxzLi"
      },
      "source": [
        "The probability of a person coming: 27.14%.\r\n",
        "\r\n",
        "The probability of three people arriving: 0.75%.\r\n",
        "\r\n",
        "The probability that no one will arrive: 66.49%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NexwguMRyBky"
      },
      "source": [
        "We know that there is considerable uncertainty in the estimates for $\\lambda$. To reflect this on the chart, we can include a 95% confidence interval at each time based on all samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6kvi68XwJDQ"
      },
      "source": [
        "burger_all_est = ss.poisson(lam_samples).pmf(arrivals_est)\n",
        "quantiles = ss.mstats.mquantiles(burger_all_est, [0.025, 0.975], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHdLo-cBwjlr"
      },
      "source": [
        "*plt.fill_between(arrivals_est, quantiles, alpha=0.7, \n",
        "                 color='steelblue', label = '95% CI')\n",
        "plt.plot(arrivals_est, entradas_est, color = 'navy', ls=\"--\", \n",
        "         lw=3, label=\"Most probable Poisson model\")\n",
        "#plt.hist(counts, density=True, bins = 5)\n",
        "plt.scatter(arrivals_est,count_norm,label=\"obs\",color=\"lime\")\n",
        "plt.legend(prop={'size':14})\n",
        "plt.xlabel('Number of arrivals every %d minutes' %n) ; plt.ylabel('Probability'); \n",
        "plt.title('Posterior Probabilty with 95% CI');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVE1YkfvyDxL"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vR9DFzcQlrsGWVONKPq4HtuUisxZMOqWZnhCKrJhMvNnIFp0Xh6OK9aurW5E8akTHFpN0oCgVCMxpPL/pub?w=908&h=369)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGJY_tkI4uco"
      },
      "source": [
        "We can assure you that with 95% confidence that our observations will fall into the blue margin, this allows us to observe that there is some uncertainty with the parameter generated by the MH algorithm.\n",
        "\n",
        "We can also plot the subsequent distribution of arrivals as a histogram based on all samples for the parameters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPy-vZNqx6z9"
      },
      "source": [
        "def burger_posterior(n_people):\n",
        "  figsize(16, 8)\n",
        "  prob = ss.poisson(lam_samples).pmf(n_people)\n",
        "  plt.hist(prob, bins=100, histtype='step', lw=4)\n",
        "  plt.title('Probability distribution for the arrival of %d people' % n_people)\n",
        "  plt.xlabel('Probability of arrivals'); plt.ylabel('Samples')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2OA9T60yLYc"
      },
      "source": [
        "burger_posterior(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjVuTK4ybWx"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vQna41i0Xr0-EjC2vyJxFuPeUljHnTIAhBPzhY_F9pONhI_T-TZGxqowVXHdo6tQY29tTus2BJNlOZT/pub?w=884&h=452)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "356eK1elzfxv"
      },
      "source": [
        "burger_posterior(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GACKa3w1yxbj"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vS5b2j684gQsa3uYe-d8gU5B6pEhnuv_6B1oV3Zam3l90Q0OCni9P0sY9xc5LYFpbqRD75H3RYjoLWb/pub?w=881&h=451)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTzebpsdzrMN"
      },
      "source": [
        "burger_posterior(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVRQ5jUEzD6M"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vSTC6fij5h74zmoXMaAfar5x0t44uz3pQeyUFi87XhZ8MLPGcbAEHTUlmPdvW5u14m6QWHLRxTT1u17/pub?w=881&h=451)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz1afN769Lgk"
      },
      "source": [
        "## Goodness and fit test\n",
        "\n",
        "Now we will verify that the $\\lambda$ parameter that we generate from the MH algorithm properly describes the data, for this we will perform a goodness and adjustment test of chi squared for discrete distributions. According to [7], we will use groupings so that the expected amount of data in each group is greater than or equal to 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSdQU3TPf8tv"
      },
      "source": [
        "# Tags\n",
        "num_arr = []\n",
        "for i in range(3):\n",
        "  num_arr.append(str(i))\n",
        "num_arr.append(\"3 or more\")\n",
        "\n",
        "# Frecuency\n",
        "counts2 = []\n",
        "for i in range(3):\n",
        "  counts2.append(counts.count(i))\n",
        "counts2.append(counts.count(3)+counts.count(4))\n",
        "\n",
        "pd.DataFrame({\"Number of arrivals\":num_arr, \"Frequency\":counts2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6RhxAc3zc4p"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vR3WPWTk3V40M_FF7DUShi3VQSCx-cSSgQ9_SX00fzd4yUAXA1Hw_PJrZ-zkyM1CWGeVzs28lsQncHj/pub?w=242&h=140)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_ty2NVh_Lw"
      },
      "source": [
        "We will assume that the data follow a Poisson distribution, so we will perform the hypothesis test trying to verify whether the data affirm a conclusion contrary to our assumption, In formal terms, we will try to show that the statistics $\\mathcal{X}^2\\leq\\mathcal{X}^2_{\\alpha,k-1-m}$, where $k$ represents the number of groups, $m$ the number of parameters in the model, $\\alpha$ the significance of the test and $\\mathcal{X}^2_{\\alpha,k-1-m}$ the value in the table for the square chi distribution with $k-1-m$ degrees of freedom. In our case, $m=1$ and $k=4$.\n",
        "\n",
        "Next, we'll calculate the estimated amounts for $\\hat{\\lambda}=\\text{lam_est}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHpaC0BTsbQy"
      },
      "source": [
        "est_am = []\n",
        "\n",
        "for i in range(3):\n",
        "  est_am.append(len(counts)*ss.poisson(lam_est).pmf(i))\n",
        "est_am.append(len(counts)-sum(est_am))\n",
        "\n",
        "pd.DataFrame({\"Number of arrivals\":num_arr, \"Frequency\":counts2, \"Estimated amounts\": est_am})"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZKqa_WczvHy"
      },
      "source": [
        "![texto del enlace](https://docs.google.com/drawings/d/e/2PACX-1vRaMpiXtK_gwUJyegi2bW9HsaDKor1M8pk-p3E5yR3WlpX0sBAcnk-y8iAmIKUSC6uuJA-Zqc9-v0n3/pub?w=374&h=140)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AZK5E7LvEgD"
      },
      "source": [
        "we'll finally calculate the value of $\\mathcal{X}^2$ and the p-value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9_wfxRvSZ1"
      },
      "source": [
        "D,p_value = ss.chisquare(counts2,est_am)   # scipy chi square\n",
        "print(\"The value of the statistic is %.4f and the p-value of the test is %.4f\" %(D,p_value))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP9em3HNz4QA"
      },
      "source": [
        "The value of the statistic is 0.2217 and the p-value of the test is 0.9740"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMqKyIyWymY1"
      },
      "source": [
        "Therefore, we can say that the Poisson distribution appropriately describes the distribution of the data, since the lowest supported significance, to reject $H_0$ is $97.40\\%$, which is an exaggeratedly large value for $\\alpha$.\n",
        "\n",
        "# Conclusions\n",
        "\n",
        "Based on the data and the tests carried out in this letter, we can conclude that the arrival of people at the Burger Dome effectively follows a distribution of Poisson, with average $\\lambda=0.40765$, this implies that on average every minute $0.40765$ people arrive at the restaurant or, equal to that on average, every $2$ minutes with $46$ seconds (approximately $1/\\lambda$), a person arrives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ApxxM7uBoII"
      },
      "source": [
        "# References\n",
        "\n",
        "[1]   Probabilidad y estadística, Liliana Blanco, Universidad Nacional de Colombia, 2004.\n",
        "\n",
        "[2]   Markov_chain_monte_carlo, WillKoehrsen, Github, 2018.\n",
        "\n",
        "[3]   Métodos de cadenas de Markov Monte Carlo, Conchi Ausín, Universidad Carlos III de Madrid, 2012.\n",
        "\n",
        "[4]   Estadística Bayesiana - Teoría y Conceptos Básicos, Eduardo Gutiérrez Peña, Universidad Nacional Autonoma de México.\n",
        "\n",
        "[5]   MCMC Methods for data modeling, Kenneth Scerri.\n",
        "\n",
        "[6]   The Metropolis Hastings Algorithm, Matthew Stephens, 2018.\n",
        "\n",
        "[7]   Probabilidad y estadística para ingeniería y ciencias básicas, Jay L. Devore, California Polytechnic State University, 2008.\n"
      ]
    }
  ]
}